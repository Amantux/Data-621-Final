---
title: "Final_Project"
author: "AZM"
date: "2024-11-15"
output: html_document
---
```{r}
library(dplyr)     #For data manipulation
library(caret)     #For machine learning models
library(tidyr)     #For data cleaning
library(ggcorrplot)
library(ggplot2)
library(dendextend)
library(reshape2)
library(polycor)
library(glmnet)


```


```{r}
# Read the CSV file
trade_register <- read.csv("trade-register.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)

# Check the first few rows to verify data import
#head(trade_register)
trade_register <- subset(trade_register, Recipient == "Ukraine")
trade_register <- trade_register %>% select(-X, -X.1, -X.2)
trade_register

```

```{r}
# Identify numeric columns in the trade_register DataFrame
numeric_columns <- sapply(trade_register, is.numeric)

# Exclude columns related to "TIV" from the numeric columns
filtered_columns <- setdiff(names(trade_register)[numeric_columns], grep("TIV", names(trade_register), value = TRUE))

# Generate scatter plots with trendlines
for (col in filtered_columns) {
  ggplot(data = trade_register, aes_string(x = col, y = "SIPRI.TIV.per.unit")) +
    geom_point(alpha = 0.7) +  # Scatter points
    geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Trendline with confidence interval
    labs(
      title = paste("Comparison of", col, "with SIPRI.TIV.per.unit"),
      x = col,
      y = "SIPRI.TIV.per.unit"
    ) +
    theme_minimal() -> plot
  
  print(plot)  # Display each plot
}

  
```


```{r}
#Summary stats for all columns
summary_stats <- summary(trade_register)

#Count NAs per column
na_counts <- sapply(trade_register, function(x) sum(is.na(x)))

#Flag irregularities
irregularities <- data.frame(
  Column = names(na_counts),
  NA_Count = na_counts,
  Zero_Count = sapply(trade_register, function(x) if(is.numeric(x)) sum(x == 0, na.rm = TRUE) else NA),
  Outliers = sapply(trade_register, function(x) {
    if(is.numeric(x)) {
      q1 <- quantile(x, 0.25, na.rm = TRUE)
      q3 <- quantile(x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      sum(x < (q1 - 1.5 * iqr) | x > (q3 + 1.5 * iqr), na.rm = TRUE)
    } else {
      NA
    }
  })
)

#Print irregularities
print("Summary Stats:")
summary_stats

print("Irregularities:")
print(irregularities)


print("Missing TIV Values")
#Filter rows with NA in SIPRI.TIV.of.delivered.weapons
na_rows <- trade_register[is.na(trade_register$SIPRI.TIV.of.delivered.weapons), ]

#View the filtered rows
print(na_rows)
```
Lets see whats going on with those weird rows with just pure ints. The are in the data. There is no explanation. I have reached out to see
Let's run a quality check to ensure that every row has a supplier and recipient

```{r}
#Create a function to flag missing or irregular values
is_missing_or_irregular <- function(x) {
  if (is.character(x)) {
    return(is.na(x) | x == "" | grepl("^\\s*$", x) | !grepl("[a-zA-Z]", x))
  } else {
    return(is.na(x))
  }
}

flagged_rows <- trade_register %>%
  filter(!grepl("[a-zA-Z]", Recipient) | !grepl("[a-zA-Z]", Supplier))

#View flagged rows
print(flagged_rows)
```

Lets remove those useless rows
```{r}
#Drop rows where Recipient or Supplier does not contain a-z
trade_register <- trade_register %>%
  filter(grepl("[a-zA-Z]", Recipient) & grepl("[a-zA-Z]", Supplier))

#Lets remove the missing flag too
fields_to_remove <- c("Missing_Flag") #Add any fields you want to remove

#Remove fields that exist in the dataset
trade_register <- trade_register %>%
  select(-all_of(intersect(fields_to_remove, names(trade_register))))

#View the cleaned dataset
head(trade_register)
```

#Cut Data for Faster Processing & Testing
Data Cut not needed as Ukrainian conflict is small enough
```{r}
#set.seed(42)  # For reproducibility
#sample_size <- 500  # Define sample size
#trade_register_sample <- trade_register[sample(1:nrow(trade_register), sample_size), ]
trade_register_sample <- trade_register
```



```{r}
#Identify categorical/numeric cols in the sample
categorical_cols <- names(Filter(function(x) is.factor(x) || is.character(x), trade_register_sample))
numeric_cols <- names(Filter(is.numeric, trade_register_sample))

#Init results df
anova_results <- data.frame(Categorical_Variable=character(),
                            Numeric_Variable=character(),
                            P_Value=numeric(),
                            stringsAsFactors=FALSE)

#Run ANOVA for each pair
for(cat in categorical_cols) {
  for(num in numeric_cols) {
    tryCatch({
      #Run ANOVA
      formula <- as.formula(paste(num, "~", cat))
      anova_result <- summary(aov(formula, data=trade_register_sample))
      
      #Extract p-value
      p_value <- anova_result[[1]]$`Pr(>F)`[1]
      
      
      
      #Store result
      anova_results <- rbind(anova_results, data.frame(
        Categorical_Variable=cat,
        Numeric_Variable=num,
        P_Value=p_value
      ))
    }, error=function(e) {
      #Handle error
      anova_results <- rbind(anova_results, data.frame(
        Categorical_Variable=cat,
        Numeric_Variable=num,
        P_Value=NA
      ))
    })
  }
}

#Drop NA rows
anova_results <- na.omit(anova_results)

#View results
print(anova_results)

anova_matrix <- dcast(anova_results, Numeric_Variable ~ Categorical_Variable, value.var = "P_Value")

# Check for correct column names after melting
anova_long <- melt(anova_matrix, id.vars = "Numeric_Variable", variable.name = "Categorical_Variable", value.name = "P_Value")

# Create a heatmap for the p-values
ggplot(anova_long, aes(x = Categorical_Variable, y = Numeric_Variable, fill = P_Value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = ifelse(!is.na(P_Value), round(P_Value, 3), "")), 
            size = 3, color = "black") +
  scale_fill_gradient2(
    low = "blue", high = "red", mid = "white", 
    midpoint = 0.05, limit = c(0, 1)
  ) +
  labs(
    title = "ANOVA-Based P-Value Heatmap",
    x = "Categorical Variable", 
    y = "Numeric Variable", 
    fill = "P-Value"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )
```


Let's go for a more advanced method: eta-squared
```{r}
data <- trade_register_sample

# Identify categorical and numeric columns
categorical_cols <- names(Filter(function(x) is.factor(x) || is.character(x), data))
numeric_cols <- names(Filter(is.numeric, data))

# Initialize results data frame
results <- data.frame(
  Variable_1 = character(),
  Variable_2 = character(),
  Eta_Squared = numeric(),
  Measure = character(),
  stringsAsFactors = FALSE
)

# Loop through all pairs of columns
for (col1 in names(data)) {
  for (col2 in names(data)) {
    if (col1 != col2) {
      tryCatch({
        # Categorical vs Numeric: Use ANOVA to compute Eta-Squared
        if (col1 %in% categorical_cols && col2 %in% numeric_cols) {
          formula <- as.formula(paste(col2, "~", col1))
          anova_model <- aov(formula, data = data)
          anova_table <- anova(anova_model)
          ss_total <- sum(anova_table$`Sum Sq`, na.rm = TRUE)
          ss_model <- anova_table$`Sum Sq`[1]
          eta_squared <- ifelse(ss_total != 0, ss_model / ss_total, NA)
          results <- rbind(results, data.frame(
            Variable_1 = col1,
            Variable_2 = col2,
            Eta_Squared = eta_squared,
            Measure = "Eta-Squared"
          ))
        }
        
        # Numeric vs Numeric: Use R-squared from Linear Regression
        if (col1 %in% numeric_cols && col2 %in% numeric_cols) {
          formula <- as.formula(paste(col2, "~", col1))
          model <- lm(formula, data = data)
          r_squared <- summary(model)$r.squared
          results <- rbind(results, data.frame(
            Variable_1 = col1,
            Variable_2 = col2,
            Eta_Squared = r_squared,
            Measure = "R-Squared"
          ))
        }
        
        # Categorical vs Categorical: Use Cramér's V
        if (col1 %in% categorical_cols && col2 %in% categorical_cols) {
          cramers_v <- cramersV(data[[col1]], data[[col2]], useNA = "no")
          results <- rbind(results, data.frame(
            Variable_1 = col1,
            Variable_2 = col2,
            Eta_Squared = cramers_v^2,  # Use square for consistency
            Measure = "Cramer's V^2"
          ))
        }
      }, error = function(e) {
        # Handle errors (e.g., missing values)
        results <- rbind(results, data.frame(
          Variable_1 = col1,
          Variable_2 = col2,
          Eta_Squared = NA,
          Measure = "Error"
        ))
      })
    }
  }
}

# View results
print(results)
```


```{r}
#Filter results to include only Eta-Squared, R-Squared, and Cramér's V^2
heatmap_data <- results %>%
  filter(Measure %in% c("Eta-Squared", "R-Squared", "Cramer's V^2")) %>%
  mutate(Eta_Squared = ifelse(is.na(Eta_Squared), 0, Eta_Squared))  # Replace NA with 0 for plotting

#Create a heatmap of effect sizes
ggplot(heatmap_data, aes(x = Variable_1, y = Variable_2, fill = Eta_Squared)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(Eta_Squared, 2)), size = 3, color = "black") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0.1, limit = c(0, 1)) +
  labs(
    title = "Effect Size Heatmap (Eta-Squared, R-Squared, Cramer's V^2)",
    x = "Variable 1",
    y = "Variable 2",
    fill = "Effect Size"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )
```
```{r}
#Filter and pivot the results to create a symmetric matrix
results_filtered <- results[results$Measure == "Eta-Squared", ]  # Filter only Eta-Squared values

#Create a full list of unique variables (to ensure symmetry)
all_vars <- unique(c(results_filtered$Variable_1, results_filtered$Variable_2))

#Create an empty symmetric matrix with all variables
empty_matrix <- matrix(0, nrow = length(all_vars), ncol = length(all_vars),
                       dimnames = list(all_vars, all_vars))

#Fill the matrix with Eta-Squared values
for (i in 1:nrow(results_filtered)) {
  var1 <- results_filtered$Variable_1[i]
  var2 <- results_filtered$Variable_2[i]
  eta_sq <- results_filtered$Eta_Squared[i]
  
  # Fill both [var1, var2] and [var2, var1] for symmetry
  empty_matrix[var1, var2] <- eta_sq
  empty_matrix[var2, var1] <- eta_sq
}

# Convert the symmetric matrix into a distance matrix
dist_matrix <- as.dist(1 - empty_matrix)  # Use (1 - Eta-Squared) as distance

# Perform hierarchical clustering
hclust_result <- hclust(dist_matrix, method = "average")  # Average linkage method

# Plot the dendrogram
plot(hclust_result, main = "Dendrogram of Variables Based on Eta-Squared",
     xlab = "", sub = "", cex = 0.8)

# Enhanced dendrogram visualization with colors
dend <- as.dendrogram(hclust_result)
dend <- color_branches(dend, k = 3)  # Color branches into 3 clusters
plot(dend, main = "Enhanced Dendrogram of Variables")
```



Let's start our model building:
Were going to remove weapon Weapon.designation in order to prevent overfitting
```{r}
#Data prep
data <- na.omit(trade_register_sample)  #Remove NAs
data <- data %>% select(-Weapon.designation)  #Drop unused col

#Convert types
data$Recipient <- as.factor(data$Recipient)
data$Supplier <- as.factor(data$Supplier)
data$status <- as.factor(data$status)
data$Weapon.description <- as.factor(data$Weapon.description)
data$Year.of.order <- scale(data$Year.of.order)  #Scale numeric

#Train-test split
set.seed(123)
train_indices <- sample(1:nrow(data), 0.8 * nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]

#Ensure all categories in train
missing_categories <- unique(data$Weapon.description[!(data$Weapon.description %in% train_data$Weapon.description)])
if (length(missing_categories) > 0) {
  for (category in missing_categories) {
    row_to_add <- test_data %>% filter(Weapon.description == category) %>% slice(1)
    train_data <- bind_rows(train_data, row_to_add)
    test_data <- test_data %>% filter(Weapon.description != category)  #Remove from test
  }
}

#Align factor levels
train_data$Weapon.description <- factor(train_data$Weapon.description, levels = levels(data$Weapon.description))
test_data$Weapon.description <- factor(test_data$Weapon.description, levels = levels(data$Weapon.description))

#Model definitions
full_model <- lm(SIPRI.TIV.per.unit ~ Supplier + Year.of.order + 
                   Number.ordered + Weapon.description + 
                   Number.delivered + Year.s..of.delivery + status, 
                 data = train_data)
null_model <- lm(SIPRI.TIV.per.unit ~ 1, data = train_data)

#Stepwise regression
stepwise_model <- step(null_model, 
                       scope = list(lower = null_model, upper = full_model), 
                       direction = "both", 
                       trace = TRUE)

#Final model AIC
final_aic <- AIC(stepwise_model)
cat("Final Model AIC:", final_aic, "\n")

#Test predictions
test_predictions <- predict(stepwise_model, newdata = test_data)

#Metrics
test_rmse <- sqrt(mean((test_data$SIPRI.TIV.per.unit - test_predictions)^2))
test_mae <- mean(abs(test_data$SIPRI.TIV.per.unit - test_predictions))
test_r2 <- 1 - sum((test_data$SIPRI.TIV.per.unit - test_predictions)^2) / 
               sum((test_data$SIPRI.TIV.per.unit - mean(test_data$SIPRI.TIV.per.unit))^2)

#Output metrics
cat("Test RMSE:", test_rmse, "\n")
cat("Test MAE:", test_mae, "\n")
cat("Test R^2:", test_r2, "\n")

```
Summary Insights:
Significant Positive Effects:

ABM/SAM Systems: Estimate 21.68 (p < 2e-16 ***)
Crucial for air defense, shielding against ballistic missiles and aircraft.

Minehunters: Estimate 17.68 (p = 5.80e-15 ***)
Essential in maritime security, particularly in clearing naval mines in the Black Sea.

SAM Systems: Estimate 11.32 (p = 8.50e-12 ***)
Vital for countering low-altitude threats like drones and helicopters.

FGA Aircraft: Estimate 11.08 (p = 3.11e-07 ***)
Versatile in achieving air superiority and close air support.

Multi-Role Radars: Estimate 5.52 (p = 0.00988 **)
Key for situational awareness, supporting integrated defense systems.

Ground Attack Aircraft: Estimate 4.28 (p = 0.04214 *)
Effective for precision strikes on high-value ground targets.

Air Search Radars: Estimate 4.01 (p = 0.01506 *)
Integral to early warning and tracking systems.

Significant Negative Effects:

Status: Second Hand: Estimate -0.66 (p = 0.05915 .)
The reduced valuation is attributed to second-hand equipment, often less effective or outdated.

Status: Second Hand but Modernized: Estimate -0.43 (p = 0.58004)
Reflects slight depreciation compared to new equipment, but modernization mitigates some loss of value.

Marginally Significant Effects:

Coastal Defense Systems: Estimate 3.68 (p = 0.08020 .)
Valuable for securing maritime boundaries but not universally impactful.

Combat Helicopters: Estimate 3.08 (p = 0.09079 .)
Useful in ground support and mobility, though less critical compared to fixed-wing aircraft.

Patrol Craft: Estimate 3.36 (p = 0.06522 .)
Contribute to maritime security but with limited strategic significance.

Status: Second Hand but Modernized: Estimate -0.43 (p = 0.58004)
Reflects slight depreciation compared to new equipment, but modernization mitigates some loss of value.

Non-Significant Effects:

   AEV: Estimate 0.61 (p = 0.72002)
ALV: Estimate -0.08 (p = 0.96955)
Anti-Ship Missile (ASM/SSM): Estimate 0.08 (p = 0.96271)
APC: Estimate -0.28 (p = 0.85082)
Armed UAV: Estimate 1.42 (p = 0.41467)
Towed Gun: Estimate -0.03 (p = 0.98448)
Reconnaissance AV: Estimate -0.20 (p = 0.92396)

```{r}
# Prepare the data: Convert formula to design matrix
X <- model.matrix(SIPRI.TIV.per.unit ~ Supplier + Year.of.order + 
                     Number.ordered + Weapon.description + 
                     Number.delivered + Year.s..of.delivery + status, 
                  data = data)[, -1] # Exclude intercept
y <- data$SIPRI.TIV.per.unit

# Train-test split
X_train <- X[train_indices, ]
y_train <- y[train_indices]
X_test <- X[-train_indices, ]
y_test <- y[-train_indices]

# Ridge regression
ridge_model <- glmnet(X_train, y_train, alpha = 0)
cv_ridge <- cv.glmnet(X_train, y_train, alpha = 0) # Cross-validation
best_lambda_ridge <- cv_ridge$lambda.min

# Lasso regression
lasso_model <- glmnet(X_train, y_train, alpha = 1)
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1) # Cross-validation
best_lambda_lasso <- cv_lasso$lambda.min

# Predictions
ridge_preds <- predict(ridge_model, s = best_lambda_ridge, newx = X_test)
lasso_preds <- predict(lasso_model, s = best_lambda_lasso, newx = X_test)

# Evaluate performance: RMSE, R^2, MAE
ridge_rmse <- sqrt(mean((ridge_preds - y_test)^2))
lasso_rmse <- sqrt(mean((lasso_preds - y_test)^2))

ridge_mae <- mean(abs(ridge_preds - y_test))
lasso_mae <- mean(abs(lasso_preds - y_test))

ridge_r2 <- 1 - sum((y_test - ridge_preds)^2) / sum((y_test - mean(y_test))^2)
lasso_r2 <- 1 - sum((y_test - lasso_preds)^2) / sum((y_test - mean(y_test))^2)

# Calculate AIC and BIC
ridge_n <- length(y_test)
ridge_sse <- sum((y_test - ridge_preds)^2)
ridge_k <- length(coef(ridge_model, s = best_lambda_ridge)) # Non-zero coefficients
ridge_aic <- ridge_n * log(ridge_sse / ridge_n) + 2 * ridge_k
ridge_bic <- ridge_n * log(ridge_sse / ridge_n) + log(ridge_n) * ridge_k

lasso_sse <- sum((y_test - lasso_preds)^2)
lasso_k <- length(coef(lasso_model, s = best_lambda_lasso)) # Non-zero coefficients
lasso_aic <- ridge_n * log(lasso_sse / ridge_n) + 2 * lasso_k
lasso_bic <- ridge_n * log(lasso_sse / ridge_n) + log(ridge_n) * lasso_k

# Output results
cat("Ridge Regression:\n")
cat("Best Lambda:", best_lambda_ridge, "\n")
cat("RMSE:", ridge_rmse, "\n")
cat("MAE:", ridge_mae, "\n")
cat("R^2:", ridge_r2, "\n")
cat("AIC:", ridge_aic, "\n")
cat("BIC:", ridge_bic, "\n\n")

cat("Lasso Regression:\n")
cat("Best Lambda:", best_lambda_lasso, "\n")
cat("RMSE:", lasso_rmse, "\n")
cat("MAE:", lasso_mae, "\n")
cat("R^2:", lasso_r2, "\n")
cat("AIC:", lasso_aic, "\n")
cat("BIC:", lasso_bic, "\n")

```
```{r}


#Ridge regression
ridge_model <- glmnet(X_train, y_train, alpha = 0)
cv_ridge <- cv.glmnet(X_train, y_train, alpha = 0) #Cross-validation
best_lambda_ridge <- cv_ridge$lambda.min
ridge_preds <- predict(ridge_model, s = best_lambda_ridge, newx = X_test)
ridge_rmse <- sqrt(mean((ridge_preds - y_test)^2)) #Ridge RMSE

#Lasso regression
lasso_model <- glmnet(X_train, y_train, alpha = 1)
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1) #Cross-validation
best_lambda_lasso <- cv_lasso$lambda.min
lasso_preds <- predict(lasso_model, s = best_lambda_lasso, newx = X_test)
lasso_rmse <- sqrt(mean((lasso_preds - y_test)^2)) #Lasso RMSE

#Compare RMSE
cat("Ridge RMSE:", ridge_rmse, "\n")
cat("Lasso RMSE:", lasso_rmse, "\n")

#QQ plots for residuals
par(mfrow = c(1, 3)) #Set up for 3 plots

#Linear model QQ plot


#Ridge regression QQ plot
qqnorm(ridge_preds - y_test, main = "Ridge Residuals")
qqline(ridge_preds - y_test)

#Lasso regression QQ plot
qqnorm(lasso_preds - y_test, main = "Lasso Residuals")
qqline(lasso_preds - y_test)

par(mfrow = c(1, 1)) #Reset plot layout


```


```{r}
# Extract Ridge coefficients
ridge_coefs <- coef(ridge_model, s = best_lambda_ridge)
ridge_coefs_df <- as.data.frame(as.matrix(ridge_coefs))
ridge_coefs_df$Attribute <- rownames(ridge_coefs_df)
rownames(ridge_coefs_df) <- NULL
colnames(ridge_coefs_df)[1] <- "Ridge_Coefficients"

# Extract Lasso coefficients
lasso_coefs <- coef(lasso_model, s = best_lambda_lasso)
lasso_coefs_df <- as.data.frame(as.matrix(lasso_coefs))
lasso_coefs_df$Attribute <- rownames(lasso_coefs_df)
rownames(lasso_coefs_df) <- NULL
colnames(lasso_coefs_df)[1] <- "Lasso_Coefficients"

# Merge coefficients into a single DataFrame for comparison
coef_comparison <- merge(ridge_coefs_df, lasso_coefs_df, by = "Attribute", all = TRUE)

# Sort by absolute value of Ridge coefficients for better readability
coef_comparison <- coef_comparison[order(abs(coef_comparison$Ridge_Coefficients), decreasing = TRUE), ]

# Display the coefficient table
coef_comparison

```





